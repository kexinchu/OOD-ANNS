# 相关系数优化建议（从-0.757到接近-1.0）

## 当前状态

- **当前相关系数**：-0.757
- **目标相关系数**：-1.0
- **差距**：0.243

## 已实施的优化

1. ✅ **增加模型复杂度**：100棵树 → 200棵树，深度10 → 15
2. ✅ **特征交互**：添加6个特征交互项（共17个特征）
3. ✅ **后处理校准**：线性校准（calibrated = 0.798 * raw - 0.002）
4. ✅ **加权采样**：分段加权，hard query采样概率提升约11倍

**结果**：相关系数从-0.757到-0.756（几乎无变化）

## 问题分析

从数据分析发现：
1. **预测方差略低**：预测std=0.228，实际std=0.235
2. **各recall范围内相关性都偏低**：所有范围内的相关性都在-0.4左右
3. **预测范围基本覆盖**：但预测值分布可能不够均匀
4. **模型可能已达到当前架构的极限**：Random Forest可能无法捕捉更复杂的非线性关系

## 进一步优化建议（按优先级排序）

### 🔥 策略1: 使用更强大的模型 ⭐⭐⭐⭐⭐

**问题**：Random Forest可能无法捕捉hardness和recall之间的复杂非线性关系

**方案**：
- **XGBoost**：梯度提升树，更强的非线性建模能力
- **LightGBM**：高效的梯度提升，支持自定义损失函数
- **神经网络**：多层感知机（MLP），可以学习任意非线性映射

**实施难度**：中等（需要集成外部库或实现新模型）
**预期效果**：相关性提升到 **-0.85 ~ -0.90**（+10-15%）

**代码示例**（XGBoost）：
```python
import xgboost as xgb
# 可以直接优化相关性作为目标
model = xgb.XGBRegressor(
    n_estimators=500,
    max_depth=10,
    learning_rate=0.1,
    objective='reg:squarederror'
)
```

---

### 🔥 策略2: 直接优化相关性作为损失函数 ⭐⭐⭐⭐⭐

**问题**：MSE损失函数不直接优化相关性

**方案**：
- **自定义损失函数**：负的相关系数作为损失
- **分位数损失**：关注极端值的准确性
- **加权MSE**：对hard query给予更高权重

**实施难度**：中等（需要修改训练循环）
**预期效果**：相关性提升到 **-0.80 ~ -0.85**（+5-10%）

**实现思路**：
```cpp
// 在训练过程中，计算预测值和实际值的相关性
// 使用负相关性作为损失，直接优化相关性
float correlation_loss = -calculate_correlation(predictions, targets);
```

---

### 🔥 策略3: 增加更多特征工程 ⭐⭐⭐⭐

**问题**：17个特征可能仍不足以捕捉所有信息

**方案**：
- **更多特征交互**：添加3-4阶交互项
- **多项式特征**：添加平方项、立方项
- **分箱特征**：将连续特征离散化
- **统计特征**：添加更多统计量（skewness, kurtosis等）

**实施难度**：低（只需修改特征提取函数）
**预期效果**：相关性提升到 **-0.78 ~ -0.82**（+3-8%）

**示例特征**：
- `nstep^2`, `avg^2`, `var^2`
- `nstep * ndis * avg`
- `(furthestNN - firstNN) / avg`
- `skewness(distances)`, `kurtosis(distances)`

---

### 🔥 策略4: 增加训练数据量 ⭐⭐⭐⭐

**问题**：100K训练样本可能不足以学习复杂模式

**方案**：
- **增加到1M或10M**：使用完整训练集
- **数据增强**：通过特征插值生成hard query样本
- **过采样hard query**：在训练集中复制hard query

**实施难度**：低（只需修改命令行参数）
**预期效果**：相关性提升到 **-0.78 ~ -0.83**（+3-10%）

---

### 🔥 策略5: 集成多个模型 ⭐⭐⭐

**问题**：单一模型可能无法捕捉所有模式

**方案**：
- **模型集成**：训练多个不同配置的模型，取平均或加权平均
- **Stacking**：使用元学习器组合多个模型
- **不同特征集的模型**：用不同特征子集训练多个模型

**实施难度**：中等（需要修改测试代码）
**预期效果**：相关性提升到 **-0.80 ~ -0.85**（+5-10%）

---

### 🔥 策略6: 分段建模 ⭐⭐⭐

**问题**：不同recall范围的查询可能需要不同的模型

**方案**：
- **按recall范围分段**：训练多个模型，每个模型负责一个recall范围
- **混合模型**：hard query用专门模型，easy query用另一个模型

**实施难度**：中等（需要修改训练和预测逻辑）
**预期效果**：相关性提升到 **-0.82 ~ -0.88**（+8-16%）

**实现思路**：
```cpp
// 训练3个模型：low recall, medium recall, high recall
if(recall < 0.3) {
    return model_low.predict(features);
} else if(recall < 0.7) {
    return model_medium.predict(features);
} else {
    return model_high.predict(features);
}
```

---

### 🔥 策略7: 深度特征学习 ⭐⭐⭐

**问题**：手工特征可能不是最优的

**方案**：
- **自编码器**：学习特征的潜在表示
- **特征选择**：使用递归特征消除找出最重要的特征
- **PCA/ICA**：降维或提取独立成分

**实施难度**：高（需要实现新算法）
**预期效果**：相关性提升到 **-0.80 ~ -0.85**（+5-12%）

---

### 🔥 策略8: 后处理优化 ⭐⭐

**问题**：简单的线性校准可能不够

**方案**：
- **分位数校准**：使用分位数映射
- **分段校准**：对不同recall范围使用不同的校准函数
- **非线性校准**：使用多项式或样条校准

**实施难度**：低（只需修改校准函数）
**预期效果**：相关性提升到 **-0.77 ~ -0.80**（+2-5%）

---

## 推荐实施顺序

### 阶段1：快速改进（预期相关性：-0.80 ~ -0.85）
1. ✅ **增加训练数据到1M**（最简单，预期+3-5%）
2. ✅ **添加更多特征交互和多项式项**（预期+3-5%）
3. ✅ **使用加权MSE损失函数**（预期+2-4%）

### 阶段2：模型升级（预期相关性：-0.85 ~ -0.90）
4. ✅ **集成XGBoost或LightGBM**（预期+5-10%）
5. ✅ **直接优化相关性作为损失**（预期+3-5%）
6. ✅ **模型集成**（预期+2-5%）

### 阶段3：深度优化（预期相关性：-0.90 ~ -0.95）
7. ✅ **分段建模**（预期+5-8%）
8. ✅ **深度特征学习**（预期+3-5%）
9. ✅ **非线性校准**（预期+1-3%）

## 预期最终效果

如果实施阶段1-2的所有策略，预期可以将相关系数从-0.757提升到 **-0.85 ~ -0.90**。

如果要达到-0.95以上，需要实施阶段3的策略，并可能需要使用更强大的模型（如XGBoost或神经网络）。

## 注意事项

1. **避免过拟合**：增加复杂度时要监控验证集性能
2. **计算资源**：更复杂的模型需要更多计算时间
3. **特征数量**：添加太多特征可能导致过拟合
4. **平衡性**：在改进hard query的同时，不要过度牺牲easy query的预测

## 最有可能成功的组合

基于当前分析，**最有可能成功**的组合是：

1. **XGBoost + 直接优化相关性**：预期相关性 **-0.88 ~ -0.92**
2. **增加训练数据到1M + 更多特征工程 + 模型集成**：预期相关性 **-0.85 ~ -0.90**
3. **分段建模 + XGBoost**：预期相关性 **-0.90 ~ -0.95**

## 结论

要达到接近-1.0的相关系数，需要：
1. **使用更强大的模型**（XGBoost或神经网络）
2. **直接优化相关性**作为损失函数
3. **大量训练数据**（1M+）
4. **深度特征工程**或**分段建模**

仅通过调整Random Forest的参数和特征，很难突破-0.80的瓶颈。

